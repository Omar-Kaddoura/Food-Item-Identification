{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9v9xxeFS_eH"
      },
      "source": [
        "# **Food Item Recognition**\n",
        "\n",
        "We will be using the following 3 models to test which one of them is ideal to our current scenario.\n",
        "*   **SVM**\n",
        "*   **Random Forest**\n",
        "*   **CNN**\n",
        "\n",
        "We need to classify images into 1 of 9 classes using these models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz_VoKowWoUb",
        "outputId": "69add0c1-b1db-460e-ba4f-7c7e14e80ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61RnKetUjBLR",
        "outputId": "1e2e776d-7445-438e-88f2-fe1a8951a5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               1\n",
            "3               2\n",
            "2               3\n",
            "4               4\n",
            "6               5\n",
            "5               6\n",
            "7               7\n",
            "8               8\n",
            "9               9\n",
            "1    category.txt\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get the path to the data folder\n",
        "data_folder = \"/content/drive/MyDrive/Food Item Recognition From Images1/data\"\n",
        "\n",
        "# Get a list of all folders in the data folder\n",
        "folders = pd.Series(os.listdir(data_folder)).sort_values()\n",
        "\n",
        "# Print the list of folders\n",
        "print(folders)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBxgMTM2SMgC"
      },
      "source": [
        "# **I. Support Vector Machines**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUV93k6LhhWD",
        "outputId": "66a6a0f2-7a26-4bc8-c5d8-da67995282b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn90RHz-Qgkf",
        "outputId": "d84d506b-aaa4-4f3d-b818-82105bb456e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.40252182347235693\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Directory containing the dataset\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "# List of classes (subdirectories) in the dataset directory\n",
        "classes = os.listdir(data_dir)\n",
        "\n",
        "# Total number of classes\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Lists to store image data and corresponding labels\n",
        "X = []  # Image data\n",
        "y = []  # Labels\n",
        "\n",
        "# Loop through each class directory\n",
        "for i, class_name in enumerate(classes):\n",
        "    # Path to the current class directory\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "\n",
        "    # Loop through each image in the class directory\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        # Path to the current image\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Check if the image is successfully loaded and not empty\n",
        "        if img is not None and img.size != 0:\n",
        "            # Resize the image to a fixed size (100x100)\n",
        "            img = cv2.resize(img, (100, 100))\n",
        "            # Convert the image to grayscale\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            # Flatten the image array to convert it into a 1D array\n",
        "            X.append(img.flatten())\n",
        "            # Append the label (class index) to the y list\n",
        "            y.append(i)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)  # Image data\n",
        "y = np.array(y)  # Labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a Support Vector Machine (SVM) classifier with a linear kernel\n",
        "svm_model = SVC(kernel='linear', decision_function_shape='ovr')\n",
        "\n",
        "# Train the SVM model using the training data\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBqybyf2Sjox"
      },
      "source": [
        "# **II. Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAv4dNoSrkG",
        "outputId": "c1dee3f8-ba09-40f6-931d-8d1ac787f516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5910418695228822\n",
            "CV Accuracy Scores: [0.50827653 0.60564752 0.54527751 0.59746589 0.50487329]\n",
            "Average CV Accuracy: 0.552308147844457\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Best parameters found:  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best cross-validated accuracy: 0.59\n",
            "Test set accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def extract_features(image_path, image_size=(100, 100)):\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image '{image_path}'\")\n",
        "            return None\n",
        "        image = cv2.resize(image, image_size)\n",
        "        # Convert image to grayscale and flatten the array\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return gray_image.flatten()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An exception occurred while processing image '{image_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "with open(os.path.join(data_folder, 'category.txt'), 'r') as category_file:\n",
        "    next(category_file)  # Skip the header line\n",
        "    for line in category_file:\n",
        "        category_id, category_name = line.strip().split('\\t')\n",
        "        category_id = int(category_id)\n",
        "        category_folder = os.path.join(data_folder, str(category_id))\n",
        "        # Iterate over images in the category folder\n",
        "        for image_file in os.listdir(category_folder):\n",
        "            image_path = os.path.join(category_folder, image_file)\n",
        "            # Extract features and append to X\n",
        "            features = extract_features(image_path)\n",
        "            X.append(features)\n",
        "            # Append corresponding label to y\n",
        "            y.append(category_id)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "#Split data into training and testing data, 0.8 and 0.2 respectively.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "#Train Random forest classifier on training data\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=32)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "#Evaluation\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#Using 10 fold cross validation\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=32)\n",
        "cv_scores = cross_val_score(rf_classifier, X, y, cv=5)\n",
        "print(f\"CV Accuracy Scores: {cv_scores}\")\n",
        "print(f\"Average CV Accuracy: {np.mean(cv_scores)}\")\n",
        "\n",
        "#Using hyperParameter tuning to find the ideal estimator.\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=32)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validated accuracy: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "#Testing the best model we got from the grid search's estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAUi7bhirzFj"
      },
      "source": [
        "Using only the testing, training data we check the accuracy of the model and it gives a moderate 0.58.\n",
        "Now we move on and add 10 fold cross validation for a more accurate accuracy score: 0.54.\n",
        "We now want to improve the model more by using hyperparameter tuning and getting the best parameters for a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN39_0t0Sr-5"
      },
      "source": [
        "# **III. Convolutional neural networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIw28UODS7su",
        "outputId": "48669289-bf41-4d1b-a883-df19c075702c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEVS_WJaBNge"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import pickle as pkl\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDU3Z9cF7lsH",
        "outputId": "a651527c-69e6-44f3-e833-e7eac719ff27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category 1 has 1650 images.\n",
            "Category 2 has 71 images.\n",
            "Category 3 has 675 images.\n",
            "Category 4 has 514 images.\n",
            "Category 5 has 27 images.\n",
            "Category 6 has 107 images.\n",
            "Category 7 has 675 images.\n",
            "Category 8 has 772 images.\n",
            "Category 9 has 660 images.\n"
          ]
        }
      ],
      "source": [
        "# Data Preparation and Preprocessing\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "\n",
        "# Check the number of images in each category\n",
        "for i in range(1, 10):\n",
        "    path = os.path.join(data_dir, str(i))\n",
        "    print(f'Category {i} has {len(os.listdir(path))} images.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ibbHc3iZTz4"
      },
      "outputs": [],
      "source": [
        "# Function to identify and remove corrupted images\n",
        "def verify_images(folder_path):\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            img = tf.io.read_file(fpath)\n",
        "            img = tf.io.decode_image(img)\n",
        "        except:\n",
        "            print(f'Removing corrupted image: {fpath}')\n",
        "            os.remove(fpath)\n",
        "\n",
        "# Apply the cleaning function to each category\n",
        "for i in range(1, 10):\n",
        "    verify_images(os.path.join(data_dir, str(i)))\n",
        "\n",
        "# Create directories for train, validation, and test sets\n",
        "sets = ['train', 'val', 'test']\n",
        "for s in sets:\n",
        "    set_path = os.path.join(data_dir, s)\n",
        "    if not os.path.exists(set_path):\n",
        "        os.makedirs(set_path)\n",
        "    for i in range(1, 10):\n",
        "        class_path = os.path.join(set_path, str(i))\n",
        "        if not os.path.exists(class_path):\n",
        "            os.makedirs(class_path)\n",
        "\n",
        "# Split the data into train, validation, and test folders\n",
        "def split_data(source, dest_train, dest_val, dest_test, split_train=0.8, split_val=0.1):\n",
        "    files = os.listdir(source)\n",
        "    np.random.shuffle(files)\n",
        "    train_idx = int(len(files) * split_train)\n",
        "    val_idx = int(len(files) * (split_train + split_val))\n",
        "    for file in files[:train_idx]:\n",
        "        shutil.copy(os.path.join(source, file), os.path.join(dest_train, file))\n",
        "    for file in files[train_idx:val_idx]:\n",
        "        shutil.copy(os.path.join(source, file), os.path.join(dest_val, file))\n",
        "    for file in files[val_idx:]:\n",
        "        shutil.copy(os.path.join(source, file), os.path.join(dest_test, file))\n",
        "\n",
        "# Apply the splitting function\n",
        "for i in range(1, 10):\n",
        "    src_folder = os.path.join(data_dir, str(i))\n",
        "    train_folder = os.path.join(data_dir, 'train', str(i))\n",
        "    val_folder = os.path.join(data_dir, 'val', str(i))\n",
        "    test_folder = os.path.join(data_dir, 'test', str(i))\n",
        "    split_data(src_folder, train_folder, val_folder, test_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkGun2qFaK-x",
        "outputId": "765e3ef4-afee-4b78-fa11-7601e1d30085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4950 images belonging to 9 classes.\n",
            "Found 984 images belonging to 9 classes.\n",
            "Epoch 1/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 2s/step - accuracy: 0.3403 - loss: 1.8998 - val_accuracy: 0.5729 - val_loss: 1.2209\n",
            "Epoch 2/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.6413 - val_accuracy: 0.7083 - val_loss: 0.9884\n",
            "Epoch 3/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 2s/step - accuracy: 0.5951 - loss: 1.1131 - val_accuracy: 0.7385 - val_loss: 0.7650\n",
            "Epoch 4/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8720 - val_accuracy: 0.7500 - val_loss: 0.7374\n",
            "Epoch 5/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 2s/step - accuracy: 0.7263 - loss: 0.7609 - val_accuracy: 0.8125 - val_loss: 0.5350\n",
            "Epoch 6/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 1.0499 - val_accuracy: 0.7083 - val_loss: 1.0054\n",
            "Epoch 7/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 2s/step - accuracy: 0.8075 - loss: 0.5701 - val_accuracy: 0.8771 - val_loss: 0.4062\n",
            "Epoch 8/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.3394 - val_accuracy: 0.9167 - val_loss: 0.3233\n",
            "Epoch 9/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 2s/step - accuracy: 0.8652 - loss: 0.3785 - val_accuracy: 0.9104 - val_loss: 0.3104\n",
            "Epoch 10/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1988 - val_accuracy: 0.9583 - val_loss: 0.2365\n",
            "Epoch 11/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 2s/step - accuracy: 0.9005 - loss: 0.2973 - val_accuracy: 0.9292 - val_loss: 0.2593\n",
            "Epoch 12/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9688 - loss: 0.2383 - val_accuracy: 0.9167 - val_loss: 0.1687\n",
            "Epoch 13/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 2s/step - accuracy: 0.9351 - loss: 0.1911 - val_accuracy: 0.9417 - val_loss: 0.2342\n",
            "Epoch 14/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3233 - val_accuracy: 1.0000 - val_loss: 0.0848\n",
            "Epoch 15/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 2s/step - accuracy: 0.9520 - loss: 0.1519 - val_accuracy: 0.9542 - val_loss: 0.1806\n",
            "Epoch 16/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1855 - val_accuracy: 0.9167 - val_loss: 0.2812\n",
            "Epoch 17/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 2s/step - accuracy: 0.9672 - loss: 0.1066 - val_accuracy: 0.9646 - val_loss: 0.1830\n",
            "Epoch 18/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0524 - val_accuracy: 0.9583 - val_loss: 0.0922\n",
            "Epoch 19/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 2s/step - accuracy: 0.9657 - loss: 0.0965 - val_accuracy: 0.9615 - val_loss: 0.1765\n",
            "Epoch 20/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.1077 - val_accuracy: 0.9583 - val_loss: 0.3459\n",
            "Epoch 21/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 2s/step - accuracy: 0.9784 - loss: 0.0745 - val_accuracy: 0.9552 - val_loss: 0.2026\n",
            "Epoch 22/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0747 - val_accuracy: 0.9583 - val_loss: 0.1810\n",
            "Epoch 23/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 2s/step - accuracy: 0.9833 - loss: 0.0593 - val_accuracy: 0.9615 - val_loss: 0.1971\n",
            "Epoch 24/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1742 - val_accuracy: 0.9583 - val_loss: 0.1099\n"
          ]
        }
      ],
      "source": [
        "# Define the architecture of the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),  # 32 filters of size 3x3, ReLU activation, input shape of (150, 150, 3)\n",
        "    MaxPooling2D(2, 2),  # Max pooling with pool size of 2x2\n",
        "    Conv2D(64, (3,3), activation='relu'),  # 64 filters of size 3x3, ReLU activation\n",
        "    MaxPooling2D(2, 2),  # Max pooling with pool size of 2x2\n",
        "    Conv2D(128, (3,3), activation='relu'),  # 128 filters of size 3x3, ReLU activation\n",
        "    MaxPooling2D(2, 2),  # Max pooling with pool size of 2x2\n",
        "    Flatten(),  # Flatten the output for dense layers\n",
        "    Dense(512, activation='relu'),  # Fully connected layer with 512 neurons, ReLU activation\n",
        "    Dropout(0.5),  # Dropout layer with dropout rate of 0.5\n",
        "    Dense(9, activation='softmax')  # Output layer with 9 neurons for classification, softmax activation\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up image data generators for training and validation data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values to the range [0, 1] for training data\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values to the range [0, 1] for validation data\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'train'),  # Path to the training data directory\n",
        "    target_size=(150, 150),  # Resize images to 150x150\n",
        "    batch_size=32,  # Batch size of 32\n",
        "    class_mode='categorical'  # Use categorical labels\n",
        ")\n",
        "\n",
        "# Flow validation images in batches of 32 using val_datagen generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'val'),  # Path to the validation data directory\n",
        "    target_size=(150, 150),  # Resize images to 150x150\n",
        "    batch_size=32,  # Batch size of 32\n",
        "    class_mode='categorical'  # Use categorical labels\n",
        ")\n",
        "\n",
        "\n",
        "# Set up Early Stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)  # Monitor validation loss and stop training if it doesn't improve for 10 epochs\n",
        "\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = len(train_generator.filenames) // train_generator.batch_size  # Dynamically adjust steps per epoch based on training data size and batch size\n",
        "validation_steps = len(val_generator.filenames) // val_generator.batch_size  # Dynamically adjust validation steps based on validation data size and batch size\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,  # Training data generator\n",
        "    steps_per_epoch=steps_per_epoch,  # Dynamically adjusted steps per epoch\n",
        "    epochs=50,  # Train for 50 epochs\n",
        "    validation_data=val_generator,  # Validation data generator\n",
        "    validation_steps=validation_steps,  # Dynamically adjusted validation steps\n",
        "    callbacks=[early_stopping]  # Early stopping callback\n",
        ")\n",
        "model_path = os.path.join('/content/drive/MyDrive', 'best_model.pkl')\n",
        "pickle.dump(best_model, open(model_path, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPZRsNVNxgTu",
        "outputId": "455cb588-ef6a-47a9-da8c-164d6f9785ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 972 images belonging to 9 classes.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 736ms/step - accuracy: 0.9529 - loss: 0.1787\n",
            "Test accuracy: 0.9578189253807068\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}